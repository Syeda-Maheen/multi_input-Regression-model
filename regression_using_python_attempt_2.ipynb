{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.dirname(os.path.abspath(\"C:\\\\Users\\\\Dell\\\\Desktop\\\\Un\\\\FYP\\\\Combining proxies of unemploynmenmt\"))\n",
    "my_file = os.path.join(folder,\"Monthly_and_Quaterly_data_of_proxes.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0         Unnamed: 1           Unnamed: 2               Unnamed: 3  \\\n",
      "0        NaN                NaN                  NaN                      NaN   \n",
      "1    QUATERS  TOTAL EXPENDITURE  CURRENT EXPENDITURE  DEVELOPMENT EXPENDITURE   \n",
      "2       FY20                NaN                  NaN                      NaN   \n",
      "3         Q1            1963072              1812572                   215220   \n",
      "4       FY19                NaN                  NaN                      NaN   \n",
      "\n",
      "          Unnamed: 4 Unnamed: 5   Unnamed: 6      Unnamed: 7  \n",
      "0                NaN        NaN          NaN             NaN  \n",
      "1  Capital Formation        LSM     deposits  Total Deposits  \n",
      "2                NaN        NaN          NaN             NaN  \n",
      "3        7.33511e+06     126.89  6.87897e+06     1.38378e+07  \n",
      "4                NaN        NaN          NaN             NaN  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(my_file)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accessing perticular sheets of excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_f = pd.ExcelFile(\"C:\\\\Users\\\\Dell\\\\Desktop\\\\Un\\\\FYP\\\\Combining proxies of unemploynmenmt/Monthly_and_Quaterly_data_of_proxes.xlsx\")\n",
    "data = my_f.parse(\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FY</th>\n",
       "      <th>Uneployment rate</th>\n",
       "      <th>Capital Formation</th>\n",
       "      <th>LSM</th>\n",
       "      <th>deposits</th>\n",
       "      <th>Total Deposits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.014121</td>\n",
       "      <td>-0.066102</td>\n",
       "      <td>0.182754</td>\n",
       "      <td>0.184198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.044365</td>\n",
       "      <td>-0.078235</td>\n",
       "      <td>0.138747</td>\n",
       "      <td>0.128225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.132687</td>\n",
       "      <td>-0.061311</td>\n",
       "      <td>0.079897</td>\n",
       "      <td>0.098088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.243797</td>\n",
       "      <td>0.082654</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.147597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FY  Uneployment rate  Capital Formation       LSM  deposits  \\\n",
       "0  2020            0.0445           0.014121 -0.066102  0.182754   \n",
       "1  2019            0.0445           0.044365 -0.078235  0.138747   \n",
       "2  2018            0.0408           0.132687 -0.061311  0.079897   \n",
       "3  2017            0.0395           0.243797  0.082654  0.100800   \n",
       "\n",
       "   Total Deposits  \n",
       "0        0.184198  \n",
       "1        0.128225  \n",
       "2        0.098088  \n",
       "3        0.147597  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FY</th>\n",
       "      <th>Uneployment rate</th>\n",
       "      <th>Capital Formation</th>\n",
       "      <th>LSM</th>\n",
       "      <th>deposits</th>\n",
       "      <th>Total Deposits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.014121</td>\n",
       "      <td>-0.066102</td>\n",
       "      <td>0.182754</td>\n",
       "      <td>0.184198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FY  Uneployment rate  Capital Formation       LSM  deposits  \\\n",
       "0  2020            0.0445           0.014121 -0.066102  0.182754   \n",
       "\n",
       "   Total Deposits  \n",
       "0        0.184198  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:][:1]\n",
    "#data = np.array(data)\n",
    "##Month = np.arange(data[:][:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Separate DataFrames for independent and Dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top three entries of train data of months are: \n",
      " [2020.0, 2019.0, 2018.0] \n",
      " \n",
      "\n",
      "Top three entries of test data of months are: \n",
      " [2017.0] \n",
      " \n",
      "\n",
      "Top three entries of train data of Unemploynment are: \n",
      " [0.0445, 0.0445, 0.0408] \n",
      " \n",
      "\n",
      "Top three entries of train data of capital formation are: \n",
      " [0.014120984769154798, 0.04436549062245243, 0.1326867212999634] \n",
      " \n",
      "\n",
      "Top three entries of test data of lsm are: \n",
      " [0.08265375467210334] \n",
      " \n",
      "\n",
      "Top three entries of train data of deposits are: \n",
      " [0.18275438113103726, 0.13874685356341376, 0.07989717475160418] \n",
      " \n",
      "\n",
      "Top three entries of train data of total deposits are: \n",
      " [0.18419753911560433, 0.12822485291943564, 0.09808827360382066] \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating DataFrames\n",
    "\n",
    "train_fy = []\n",
    "train_cap_for = []\n",
    "train_lsm = []\n",
    "train_dep = []\n",
    "train_tot_dep = []\n",
    "test_fy = []\n",
    "test_cap_for = []\n",
    "test_lsm = []\n",
    "test_dep = []\n",
    "test_tot_dep = []\n",
    "train_une = []\n",
    "test_une = []\n",
    "\n",
    "# Nested Loop for inputing data in DataFrames\n",
    "\n",
    "for i in np.array(data,dtype = None, ndmin = 2):\n",
    "    b = 1\n",
    "    for a in i:\n",
    "        if b == 1:\n",
    "            train_fy.append(a)\n",
    "            b+= 1\n",
    "        elif b == 2:\n",
    "            train_une.append(a)\n",
    "            b+= 1\n",
    "        elif b == 3:\n",
    "            train_cap_for.append(a)\n",
    "            b+= 1\n",
    "        elif b == 4:\n",
    "            train_lsm.append(a)\n",
    "            b+= 1\n",
    "        elif b == 5:\n",
    "            train_dep.append(a)\n",
    "            b+= 1\n",
    "        elif b == 6:\n",
    "            train_tot_dep.append(a)\n",
    "            b+= 1  \n",
    "       \n",
    "# Variables\n",
    "\n",
    "# Train data for Months \n",
    "test_fy = train_fy[3:]\n",
    "train_fy = train_fy[:3]\n",
    "print(\"Top three entries of train data of months are: \\n\",train_fy,\"\\n \\n\")\n",
    "print(\"Top three entries of test data of months are: \\n\",test_fy,\"\\n \\n\")\n",
    "\n",
    "# Train data for Unemployment\n",
    "test_une = train_une[3:]\n",
    "train_une = train_une[:3]\n",
    "print(\"Top three entries of train data of Unemploynment are: \\n\",train_une,\"\\n \\n\")\n",
    "\n",
    "# Train data for Capital Formation\n",
    "test_cap_for = train_cap_for[3:]\n",
    "train_cap_for = train_cap_for[:3]\n",
    "print(\"Top three entries of train data of capital formation are: \\n\",train_cap_for,\"\\n \\n\")\n",
    "\n",
    "# Train data for LSM\n",
    "test_lsm = train_lsm[3:]\n",
    "train_lsm = train_lsm[:3]\n",
    "print(\"Top three entries of test data of lsm are: \\n\",test_lsm,\"\\n \\n\")\n",
    "\n",
    "# Train data for Deposits\n",
    "test_dep = train_dep[3:]\n",
    "train_dep = train_dep[:3]\n",
    "print(\"Top three entries of train data of deposits are: \\n\",train_dep,\"\\n \\n\")\n",
    "\n",
    "\n",
    "# Train data for Total Deposits\n",
    "test_tot_dep = train_tot_dep[3:]\n",
    "train_tot_dep = train_tot_dep[:3]\n",
    "print(\"Top three entries of train data of total deposits are: \\n\",train_tot_dep,\"\\n \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessig "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to array to normalize data operation can't perform \n",
    "\n",
    "train_fy = np.array(train_fy)\n",
    "train_cap_for = np.array(train_cap_for)\n",
    "train_une = np.array(train_une)\n",
    "train_lsm = np.array(train_lsm, dtype = np.float64)\n",
    "train_dep = np.array(train_dep)\n",
    "train_tot_dep = np.array(train_tot_dep)\n",
    "test_fy = np.array(test_fy)\n",
    "test_cap_for = np.array(test_cap_for)\n",
    "test_une = np.array(test_une)\n",
    "test_lsm = np.array(test_lsm, dtype = np.float64)\n",
    "test_dep = np.array(test_dep)\n",
    "test_tot_dep = np.array(test_tot_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_cap_for.mean(axis=0)\n",
    "train_cap_for -= mean\n",
    "std = train_cap_for.std(axis=0)\n",
    "train_cap_for /= std\n",
    "test_cap_for -= mean\n",
    "test_cap_for /= std\n",
    "\n",
    "mean = train_lsm.mean(axis=0)\n",
    "train_lsm -= mean\n",
    "std = train_lsm.std(axis=0)\n",
    "train_lsm /= std\n",
    "test_lsm -= mean\n",
    "test_lsm /= std\n",
    "\n",
    "mean = train_dep.mean(axis=0)\n",
    "train_dep -= mean\n",
    "std = train_dep.std(axis=0)\n",
    "train_dep /= std\n",
    "test_dep -= mean\n",
    "test_dep /= std\n",
    "\n",
    "mean = train_tot_dep.mean(axis=0)\n",
    "train_tot_dep -= mean\n",
    "std = train_tot_dep.std(axis=0)\n",
    "train_tot_dep /= std\n",
    "test_tot_dep -= mean\n",
    "test_tot_dep /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def model_cap_for():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(3, activation = \"relu\" , input_shape = (3,1)))\n",
    "    model.add(layers.Dense(2, activation = \"relu\"))\n",
    "#   model.add(layers.Dense(1))     final layer with 1 neuron will be add to combined model\n",
    "    return model.output\n",
    "\n",
    "def model_lsm():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(2, activation = \"relu\" , input_shape = (3,1)))\n",
    "    model.add(layers.Dense(2, activation = \"relu\"))\n",
    "    return model.output\n",
    "\n",
    "def model_dep():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(3, activation = \"relu\" , input_shape = (3,1)))\n",
    "    model.add(layers.Dense(4, activation = \"relu\"))\n",
    "    return model.output\n",
    "\n",
    "def model_tot_dep():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(1, activation = \"relu\" , input_shape = (3,1)))\n",
    "    model.add(layers.Dense(1, activation = \"relu\"))\n",
    "    return model.output\n",
    "\n",
    "def model(combined):\n",
    "    model1 = models.Sequential()\n",
    "    model1.add(layers.Dense(2, activation = \"relu\", input_shape = (combined)))\n",
    "    model1.add(layers.Dense(1, activation = \"linear\"))\n",
    "    model1.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate_6/Identity:0\", shape=(None, 3, 9), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot iterate over a tensor with unknown first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f12180f8e726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_cap_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_lsm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_dep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_tot_dep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m model1.fit(x = [train_cap_for ,train_lsm , train_dep, train_tot_dep], y = train_une,\n\u001b[0;32m      9\u001b[0m epochs=1, batch_size=1)\n",
      "\u001b[1;32m<ipython-input-18-5cb780a442d4>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(combined)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m     super(Dense, self).__init__(\n\u001b[1;32m--> 994\u001b[1;33m         activity_regularizer=regularizers.get(activity_regularizer), **kwargs)\n\u001b[0m\u001b[0;32m    995\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mbatch_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_shape'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m       raise TypeError(\n\u001b[1;32m--> 556\u001b[1;33m           \"Cannot iterate over a tensor with unknown first dimension.\")\n\u001b[0m\u001b[0;32m    557\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m       \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot iterate over a tensor with unknown first dimension."
     ]
    }
   ],
   "source": [
    "model_cap_for()\n",
    "model_lsm()\n",
    "model_dep()\n",
    "model_tot_dep()\n",
    "combined = layers.concatenate([model_cap_for(), model_lsm(), model_dep(), model_tot_dep()])\n",
    "print(combined)\n",
    "model1 = model(combined)\n",
    "model1.fit(x = [train_cap_for ,train_lsm , train_dep, train_tot_dep], y = train_une,\n",
    "epochs=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# define two sets of inputs\n",
    "inputA = Input(40,1)\n",
    "inputB = Input(40,1)\n",
    "inputC = Input(40,1)\n",
    "inputD = Input(40,1)\n",
    "\n",
    "# the first branch operates on the first input\n",
    "x = Dense(8, activation=\"relu\")(inputA)\n",
    "x = Dense(4, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(64, activation=\"relu\")(inputB)\n",
    "y = Dense(32, activation=\"relu\")(y)\n",
    "y = Dense(4, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "# the second branch opreates on the third input\n",
    "u = Dense(64, activation=\"relu\")(inputC)\n",
    "u = Dense(32, activation=\"relu\")(u)\n",
    "u = Dense(4, activation=\"relu\")(u)\n",
    "u = Model(inputs=inputC, outputs=u)\n",
    "\n",
    "# the second branch opreates on the fourth input\n",
    "v = Dense(64, activation=\"relu\")(inputD)\n",
    "v = Dense(32, activation=\"relu\")(v)\n",
    "v = Dense(4, activation=\"relu\")(v)\n",
    "v = Model(inputs=inputD, outputs=v)\n",
    "\n",
    "# combine the output of the two branches\n",
    "combined = tensorflow.keras.layers.concatenate([x.output, y.output, u.output, v.output])\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(2, activation=\"relu\")(combined)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = Model(inputs=[x.input, y.input, u.input, v.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, partial_train_targets,\n",
    "epochs=num_epochs, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_for[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
